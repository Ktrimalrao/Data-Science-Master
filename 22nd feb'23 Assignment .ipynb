{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b8884ec-e68f-4cb0-afa2-191a5db37072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"***************************** 22nd feb'23 Assignment *****************************\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"***************************** 22nd feb'23 Assignment *****************************\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c523a131-8d4c-4d02-bee6-84ada8e8d148",
   "metadata": {},
   "source": [
    "# Image Scrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe4dbfd-ac21-4971-8e94-7a5ef57d1a8c",
   "metadata": {},
   "source": [
    "## Go to this given URL and solve the following questions\n",
    "### URL: https://www.youtube.com/@PW-Foundation/videos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46a79c-5864-49ee-a493-616338bfe08f",
   "metadata": {},
   "source": [
    "#### Q1. Write a python program to extract the video URL of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65022860-f86a-46b1-a06f-41cd4e3174ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.28.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (4.11.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "! pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2af717a8-99e4-4b1c-a5c7-08e5a0a172c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    video_links = soup.find_all(\"a\", class_=\"yt-simple-endpoint style-scope ytd-grid-video-renderer\")\n",
    "    \n",
    "    # Extract the first five video URLs\n",
    "    first_five_videos = []\n",
    "    for link in video_links[:5]:\n",
    "        video_url = \"https://www.youtube.com\" + link[\"href\"]\n",
    "        first_five_videos.append(video_url)\n",
    "    \n",
    "    for idx, video_url in enumerate(first_five_videos, start=1):\n",
    "        print(f\"Video {idx}: {video_url}\")\n",
    "else:\n",
    "    print(\"Failed to fetch the page.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4284f-c259-41c8-b6cd-23b0adb4e342",
   "metadata": {},
   "source": [
    "#### Q2. Write a python program to extract the URL of the video thumbnails of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75a0b1eb-af50-4112-965d-75c72d54e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    video_thumbnails = soup.find_all(\"img\", class_=\"style-scope yt-img-shadow\")\n",
    "    \n",
    "    # Extract the URLs of video thumbnails for the first five videos\n",
    "    first_five_thumbnails = []\n",
    "    for thumbnail in video_thumbnails[:5]:\n",
    "        thumbnail_url = thumbnail[\"src\"]\n",
    "        first_five_thumbnails.append(thumbnail_url)\n",
    "    \n",
    "    for idx, thumbnail_url in enumerate(first_five_thumbnails, start=1):\n",
    "        print(f\"Thumbnail {idx}: {thumbnail_url}\")\n",
    "else:\n",
    "    print(\"Failed to fetch the page.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1703f0a0-5394-4d6d-8c09-fc9800a6074b",
   "metadata": {},
   "source": [
    "#### Q3. Write a python program to extract the title of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa782de6-e99d-4bef-a981-80cd763fac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    video_titles = soup.find_all(\"a\", class_=\"yt-simple-endpoint style-scope ytd-grid-video-renderer\")\n",
    "    \n",
    "    # Extract the titles of the first five videos\n",
    "    first_five_titles = []\n",
    "    for title in video_titles[:5]:\n",
    "        video_title = title.get(\"title\")\n",
    "        first_five_titles.append(video_title)\n",
    "    \n",
    "    for idx, video_title in enumerate(first_five_titles, start=1):\n",
    "        print(f\"Video {idx} Title: {video_title}\")\n",
    "else:\n",
    "    print(\"Failed to fetch the page.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70775444-4321-4e61-a945-77896831b80a",
   "metadata": {},
   "source": [
    "#### Q4. Write a python program to extract the number of views of the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a00c4ffb-296a-4f53-a37f-fba7742c4dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    video_views = soup.find_all(\"span\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "    \n",
    "    # Extract the number of views of the first five videos\n",
    "    first_five_views = []\n",
    "    for view in video_views[:5]:\n",
    "        view_text = view.get_text()\n",
    "        if \"views\" in view_text:\n",
    "            num_views = view_text.split()[0]\n",
    "            first_five_views.append(num_views)\n",
    "    \n",
    "    for idx, num_views in enumerate(first_five_views, start=1):\n",
    "        print(f\"Video {idx} Views: {num_views}\")\n",
    "else:\n",
    "    print(\"Failed to fetch the page.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2fab74-3aec-4a63-964d-7398a71ac644",
   "metadata": {},
   "source": [
    "#### Q5. Write a python program to extract the time of posting of video for the first five videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f3d3d90-bad6-422f-b6ea-15ff78a75b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    video_post_times = soup.find_all(\"div\", class_=\"style-scope ytd-grid-video-renderer\")\n",
    "    \n",
    "    # Extract the time of posting for the first five videos\n",
    "    first_five_post_times = []\n",
    "    for post_time in video_post_times[:5]:\n",
    "        post_time_text = post_time.get_text()\n",
    "        if \"ago\" in post_time_text:\n",
    "            first_five_post_times.append(post_time_text)\n",
    "    \n",
    "    for idx, post_time in enumerate(first_five_post_times, start=1):\n",
    "        print(f\"Video {idx} Posted: {post_time}\")\n",
    "else:\n",
    "    print(\"Failed to fetch the page.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b65694-2ebf-4d2d-9d3a-47093142ba81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
